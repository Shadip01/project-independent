{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2024-10\n",
      "1    2024-10\n",
      "2    2024-10\n",
      "3    2024-10\n",
      "4    2024-10\n",
      "Name: Month/Year, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = '../DATASETS/RNNs-datasets/data_reports_monthly.csv'\n",
    "database = pd.read_csv(file_name)\n",
    "\n",
    "database.replace('-', np.nan, inplace=True)  # Replace '-' with NaN\n",
    "database = database.dropna(subset=['Trips Per Day', 'Unique Vehicles', 'Unique Drivers', 'License Class'])\n",
    "database['Trips Per Day'] = database['Trips Per Day'].replace({',': ''}, regex=True).astype(float)\n",
    "database['Unique Vehicles'] = database['Unique Vehicles'].replace({',': ''}, regex=True).astype(float)\n",
    "database['Unique Drivers'] = database['Unique Drivers'].replace({',': ''}, regex=True).astype(float)\n",
    "print(database['Month/Year'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Mappings:\n",
      "0: 2010-01\n",
      "1: 2010-02\n",
      "2: 2010-03\n",
      "3: 2010-04\n",
      "4: 2010-05\n",
      "5: 2010-06\n",
      "6: 2010-07\n",
      "7: 2010-08\n",
      "8: 2010-09\n",
      "9: 2010-10\n",
      "10: 2010-11\n",
      "11: 2010-12\n",
      "12: 2011-01\n",
      "13: 2011-02\n",
      "14: 2011-03\n",
      "15: 2011-04\n",
      "16: 2011-05\n",
      "17: 2011-06\n",
      "18: 2011-07\n",
      "19: 2011-08\n",
      "20: 2011-09\n",
      "21: 2011-10\n",
      "22: 2011-11\n",
      "23: 2011-12\n",
      "24: 2012-01\n",
      "25: 2012-02\n",
      "26: 2012-03\n",
      "27: 2012-04\n",
      "28: 2012-05\n",
      "29: 2012-06\n",
      "30: 2012-07\n",
      "31: 2012-08\n",
      "32: 2012-09\n",
      "33: 2012-10\n",
      "34: 2012-11\n",
      "35: 2012-12\n",
      "36: 2013-01\n",
      "37: 2013-02\n",
      "38: 2013-03\n",
      "39: 2013-04\n",
      "40: 2013-05\n",
      "41: 2013-06\n",
      "42: 2013-07\n",
      "43: 2013-08\n",
      "44: 2013-09\n",
      "45: 2013-10\n",
      "46: 2013-11\n",
      "47: 2013-12\n",
      "48: 2014-01\n",
      "49: 2014-02\n",
      "50: 2014-03\n",
      "51: 2014-04\n",
      "52: 2014-05\n",
      "53: 2014-06\n",
      "54: 2014-07\n",
      "55: 2014-08\n",
      "56: 2014-09\n",
      "57: 2014-10\n",
      "58: 2014-11\n",
      "59: 2014-12\n",
      "60: 2015-01\n",
      "61: 2015-02\n",
      "62: 2015-03\n",
      "63: 2015-04\n",
      "64: 2015-05\n",
      "65: 2015-06\n",
      "66: 2015-07\n",
      "67: 2015-08\n",
      "68: 2015-09\n",
      "69: 2015-10\n",
      "70: 2015-11\n",
      "71: 2015-12\n",
      "72: 2016-01\n",
      "73: 2016-02\n",
      "74: 2016-03\n",
      "75: 2016-04\n",
      "76: 2016-05\n",
      "77: 2016-06\n",
      "78: 2016-07\n",
      "79: 2016-08\n",
      "80: 2016-09\n",
      "81: 2016-10\n",
      "82: 2016-11\n",
      "83: 2016-12\n",
      "84: 2017-01\n",
      "85: 2017-02\n",
      "86: 2017-03\n",
      "87: 2017-04\n",
      "88: 2017-05\n",
      "89: 2017-06\n",
      "90: 2017-07\n",
      "91: 2017-08\n",
      "92: 2017-09\n",
      "93: 2017-10\n",
      "94: 2017-11\n",
      "95: 2017-12\n",
      "96: 2018-01\n",
      "97: 2018-02\n",
      "98: 2018-03\n",
      "99: 2018-04\n",
      "100: 2018-05\n",
      "101: 2018-06\n",
      "102: 2018-07\n",
      "103: 2018-08\n",
      "104: 2018-09\n",
      "105: 2018-10\n",
      "106: 2018-11\n",
      "107: 2018-12\n",
      "108: 2019-01\n",
      "109: 2019-02\n",
      "110: 2019-03\n",
      "111: 2019-04\n",
      "112: 2019-05\n",
      "113: 2019-06\n",
      "114: 2019-07\n",
      "115: 2019-08\n",
      "116: 2019-09\n",
      "117: 2019-10\n",
      "118: 2019-11\n",
      "119: 2019-12\n",
      "120: 2020-01\n",
      "121: 2020-02\n",
      "122: 2020-03\n",
      "123: 2020-04\n",
      "124: 2020-05\n",
      "125: 2020-06\n",
      "126: 2020-07\n",
      "127: 2020-08\n",
      "128: 2020-09\n",
      "129: 2020-10\n",
      "130: 2020-11\n",
      "131: 2020-12\n",
      "132: 2021-01\n",
      "133: 2021-02\n",
      "134: 2021-03\n",
      "135: 2021-04\n",
      "136: 2021-05\n",
      "137: 2021-06\n",
      "138: 2021-07\n",
      "139: 2021-08\n",
      "140: 2021-09\n",
      "141: 2021-10\n",
      "142: 2021-11\n",
      "143: 2021-12\n",
      "144: 2022-01\n",
      "145: 2022-02\n",
      "146: 2022-03\n",
      "147: 2022-04\n",
      "148: 2022-05\n",
      "149: 2022-06\n",
      "150: 2022-07\n",
      "151: 2022-08\n",
      "152: 2022-09\n",
      "153: 2022-10\n",
      "154: 2022-11\n",
      "155: 2022-12\n",
      "156: 2023-01\n",
      "157: 2023-02\n",
      "158: 2023-03\n",
      "159: 2023-04\n",
      "160: 2023-05\n",
      "161: 2023-06\n",
      "162: 2023-07\n",
      "163: 2023-08\n",
      "164: 2023-09\n",
      "165: 2023-10\n",
      "166: 2023-11\n",
      "167: 2023-12\n",
      "168: 2024-01\n",
      "169: 2024-02\n",
      "170: 2024-03\n",
      "171: 2024-04\n",
      "172: 2024-05\n",
      "173: 2024-06\n",
      "174: 2024-07\n",
      "175: 2024-08\n",
      "176: 2024-09\n",
      "177: 2024-10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(database['Month/Year'])  #\n",
    "\n",
    "# Check the mappings\n",
    "print(\"Correct Mappings:\")\n",
    "for encoded, original in enumerate(encoder.classes_):\n",
    "    print(f\"{encoded}: {original}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "database['License Class'] = encoder.fit_transform(database['License Class'])\n",
    "database['Month/Year'] = encoder.fit_transform(database['Month/Year'])\n",
    "\n",
    "# Features and target\n",
    "features = database[['Trips Per Day', 'Unique Vehicles', 'Unique Drivers', 'License Class']].values\n",
    "target = database['Month/Year'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create sequences\n",
    "timesteps = 7\n",
    "\n",
    "def create_sequences(features, target, timesteps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - timesteps):\n",
    "        X.append(features[i : i + timesteps])\n",
    "        y.append(target[i + timesteps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(features_scaled, target, timesteps)\n",
    "\n",
    "# One-hot encode target\n",
    "num_classes = len(np.unique(y))\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 64)                4416      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 177)               5841      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12337 (48.19 KB)\n",
      "Trainable params: 12337 (48.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN model\n",
    "model = Sequential([\n",
    "    SimpleRNN(64, activation='relu', input_shape=(timesteps, X_train.shape[2]), return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 5.1836 - accuracy: 0.0040 - val_loss: 5.1828 - val_accuracy: 0.0080\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.1571 - accuracy: 0.0101 - val_loss: 5.1842 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.1428 - accuracy: 0.0040 - val_loss: 5.1894 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.1171 - accuracy: 0.0121 - val_loss: 5.2049 - val_accuracy: 0.0080\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.0722 - accuracy: 0.0080 - val_loss: 5.2544 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.0296 - accuracy: 0.0121 - val_loss: 5.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.9829 - accuracy: 0.0040 - val_loss: 5.3136 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.9322 - accuracy: 0.0060 - val_loss: 5.3001 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.8944 - accuracy: 0.0101 - val_loss: 5.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.8398 - accuracy: 0.0161 - val_loss: 5.2758 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.7959 - accuracy: 0.0201 - val_loss: 5.3141 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.7780 - accuracy: 0.0080 - val_loss: 5.5047 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.7498 - accuracy: 0.0040 - val_loss: 5.3923 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.7366 - accuracy: 0.0141 - val_loss: 5.3234 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.6994 - accuracy: 0.0221 - val_loss: 5.3787 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.6694 - accuracy: 0.0201 - val_loss: 5.5750 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.6312 - accuracy: 0.0282 - val_loss: 5.5136 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.5699 - accuracy: 0.0221 - val_loss: 5.6730 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.5246 - accuracy: 0.0262 - val_loss: 5.7141 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.4689 - accuracy: 0.0221 - val_loss: 5.7405 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 955us/step - loss: 6.2016 - accuracy: 0.0000e+00\n",
      "Test Loss: 6.2016, Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_month(features):\n",
    "    # Ensure features are properly shaped (7 timesteps, 4 features)\n",
    "    features = np.array(features)\n",
    "    if features.shape != (timesteps, features.shape[1]):\n",
    "        raise ValueError(f\"Input must have shape ({timesteps}, {features.shape[1]}).\")\n",
    "    \n",
    "    # Normalize and reshape features\n",
    "    features_flat = features.reshape(-1, features.shape[-1])  # Flatten to 2D\n",
    "    features_scaled = scaler.transform(features_flat)  # Scale features\n",
    "    features_reshaped = features_scaled.reshape((1, timesteps, features.shape[-1]))  # Reshape back to 3D\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(features_reshaped)\n",
    "    predicted_class = np.argmax(prediction)  # Get the predicted class index\n",
    "\n",
    "    # Decode the predicted class back to the original label\n",
    "    return encoder.inverse_transform([predicted_class])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "Predicted Month/Year: 2020-04\n"
     ]
    }
   ],
   "source": [
    "# Example input: 7 timesteps, each with 4 features\n",
    "example_features = [\n",
    "    [50, 10, 8, 3],  # Timestep 1\n",
    "    [52, 12, 9, 4],  # Timestep 2\n",
    "    [48, 11, 7, 3],  # Timestep 3\n",
    "    [49, 9, 8, 2],   # Timestep 4\n",
    "    [51, 10, 9, 3],  # Timestep 5\n",
    "    [50, 11, 8, 3],  # Timestep 6\n",
    "    [49, 10, 8, 3]   # Timestep 7\n",
    "]\n",
    "\n",
    "# Predict the \"Month/Year\"\n",
    "predicted_month = predict_month(example_features)\n",
    "print(f\"Predicted Month/Year: {predicted_month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
